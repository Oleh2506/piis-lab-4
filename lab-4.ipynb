{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a900aa94-7133-4e07-9631-b2e088926367",
   "metadata": {},
   "source": [
    "# Lab-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5fa32d-a232-4419-bca6-d43d6113c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51dcf3c-8eec-4f58-88ac-39ebacfc8871",
   "metadata": {},
   "source": [
    "### Import data and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38b9ae2-9692-4daf-9b6c-2ee6412c958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resources/data.csv\")\n",
    "df.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)\n",
    "df['diagnosis']=df['diagnosis'].astype('category').cat.codes\n",
    "X = df.drop(['diagnosis'], axis = 1)\n",
    "y = df['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e88c55-e850-48bf-85d7-b62075481703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4de183-68a6-48f6-8d1f-41221592a5c5",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b866f-eca9-4f84-8be0-0d2ddf1d543e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9b8bf1-b52d-489a-8324-54259408dbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base Decision Tree model:  94.15\n",
      "Accuracy of tuned Decision Tree model:  97.08\n"
     ]
    }
   ],
   "source": [
    "base_dt = DecisionTreeClassifier()\n",
    "base_dt.fit(X_train, y_train)\n",
    "base_dt_y_pred = base_dt.predict(X_test)\n",
    "\n",
    "parameters = {'max_features': ['log2', 'sqrt', 'auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10, 50], \n",
    "              'min_samples_split': [2, 3, 50, 100],\n",
    "              'min_samples_leaf': [1, 5, 8, 10]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(base_dt, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "tuned_dt = grid_obj.best_estimator_\n",
    "tuned_dt.fit(X_train, y_train)\n",
    "tuned_dt_y_pred = tuned_dt.predict(X_test)\n",
    "\n",
    "acc_base_dt = round(metrics.accuracy_score(y_test, base_dt_y_pred) * 100, 2)\n",
    "acc_tuned_dt = round(metrics.accuracy_score(y_test, tuned_dt_y_pred) * 100, 2)\n",
    "\n",
    "print('Accuracy of base Decision Tree model: ', acc_base_dt)\n",
    "print('Accuracy of tuned Decision Tree model: ', acc_tuned_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d261e9-b341-450a-8b9a-47ceb523b287",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b24b8b-716e-46ac-bec8-88f01897a7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base Random Forest model:  96.49\n",
      "Accuracy of tuned Random Forest model:  97.08\n"
     ]
    }
   ],
   "source": [
    "base_rf = RandomForestClassifier()\n",
    "base_rf.fit(X_train, y_train)\n",
    "base_rf_y_pred = base_rf.predict(X_test)\n",
    "\n",
    "parameters = {'n_estimators': [4, 6, 9, 10, 15], \n",
    "              'max_features': ['log2', 'sqrt', 'auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1, 5, 8]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(base_rf, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "tuned_rf = grid_obj.best_estimator_\n",
    "tuned_rf.fit(X_train, y_train)\n",
    "tuned_rf_y_pred = tuned_rf.predict(X_test)\n",
    "\n",
    "acc_base_rf = round(metrics.accuracy_score(y_test, base_rf_y_pred) * 100, 2)\n",
    "acc_tuned_rf = round(metrics.accuracy_score(y_test, tuned_rf_y_pred) * 100, 2)\n",
    "\n",
    "print('Accuracy of base Random Forest model: ', acc_base_rf)\n",
    "print('Accuracy of tuned Random Forest model: ', acc_tuned_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3180e-ab4a-418c-a514-dd665579455e",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8131c904-0275-4a15-b97b-a6ba428b3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base SVC model:  97.66\n",
      "Accuracy of tuned SVC model:  97.66\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "base_svc = SVC()\n",
    "base_svc.fit(X_train, y_train)\n",
    "base_svc_y_pred = base_svc.predict(X_test)\n",
    "\n",
    "parameters = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "grid_obj = GridSearchCV(base_svc, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "tuned_svc = grid_obj.best_estimator_\n",
    "tuned_svc.fit(X_train, y_train)\n",
    "tuned_svc_y_pred = tuned_svc.predict(X_test)\n",
    "\n",
    "acc_base_svc = round(metrics.accuracy_score(y_test, base_svc_y_pred) * 100, 2)\n",
    "acc_tuned_svc = round(metrics.accuracy_score(y_test, tuned_svc_y_pred) * 100, 2)\n",
    "\n",
    "print('Accuracy of base SVC model: ', acc_base_svc)\n",
    "print('Accuracy of tuned SVC model: ', acc_tuned_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5700d3-9bc6-4ffd-8b59-912ac39b672d",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb3b6b8-cb43-4da0-b69a-c6839bff39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base KNN model:  95.91\n",
      "Accuracy of tuned KNN model:  95.91\n"
     ]
    }
   ],
   "source": [
    "base_knn = KNeighborsClassifier()\n",
    "base_knn.fit(X_train, y_train)\n",
    "base_knn_y_pred = base_knn.predict(X_test)\n",
    "\n",
    "parameters = {'n_neighbors': [3, 4, 5, 10], \n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'leaf_size' : [10, 20, 30, 50]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(base_knn, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "tuned_knn = grid_obj.best_estimator_\n",
    "tuned_knn.fit(X_train, y_train)\n",
    "tuned_knn_y_pred = tuned_knn.predict(X_test)\n",
    "\n",
    "acc_base_knn = round(metrics.accuracy_score(y_test, base_knn_y_pred) * 100, 2)\n",
    "acc_tuned_knn = round(metrics.accuracy_score(y_test, tuned_knn_y_pred) * 100, 2)\n",
    "\n",
    "print('Accuracy of base KNN model: ', acc_base_knn)\n",
    "print('Accuracy of tuned KNN model: ', acc_tuned_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b4ba5-9be4-4d0a-a1f3-772d106b3602",
   "metadata": {},
   "source": [
    "### Tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2626d610-95ce-43cc-920e-0b55964965a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base Support Vector Machines</td>\n",
       "      <td>97.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Support Vector Machines</td>\n",
       "      <td>97.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>97.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>97.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base Random Forest</td>\n",
       "      <td>96.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Base K-Nearest Neighbors</td>\n",
       "      <td>95.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned K-Nearest Neighbors</td>\n",
       "      <td>95.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Decision Tree</td>\n",
       "      <td>94.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy\n",
       "4   Base Support Vector Machines     97.66\n",
       "5  Tuned Support Vector Machines     97.66\n",
       "1            Tuned Decision Tree     97.08\n",
       "3            Tuned Random Forest     97.08\n",
       "2             Base Random Forest     96.49\n",
       "6       Base K-Nearest Neighbors     95.91\n",
       "7      Tuned K-Nearest Neighbors     95.91\n",
       "0             Base Decision Tree     94.15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Base Decision Tree', 'Tuned Decision Tree', 'Base Random Forest', 'Tuned Random Forest',\n",
    "              'Base Support Vector Machines', 'Tuned Support Vector Machines', 'Base K-Nearest Neighbors', 'Tuned K-Nearest Neighbors'],\n",
    "    'Accuracy': [acc_base_dt, acc_tuned_dt, acc_base_rf, acc_tuned_rf, \n",
    "              acc_base_svc, acc_tuned_svc, acc_base_knn, acc_tuned_knn]})\n",
    "\n",
    "models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3fdbf1-4d02-45ac-84f3-b4829642806a",
   "metadata": {},
   "source": [
    "## Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20af9a29-11e5-491b-bb42-132b93dbe189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Hard Voting model: 0.988304\n",
      "Accuracy of Soft Voting model: 0.988304\n"
     ]
    }
   ],
   "source": [
    "estimators = [] \n",
    "estimators.append(('LR', LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=200))) \n",
    "estimators.append(('SVC', SVC(gamma='auto', probability=True))) \n",
    "estimators.append(('DTC', DecisionTreeClassifier()))\n",
    "\n",
    "hard_voting = VotingClassifier(estimators=estimators, voting='hard') \n",
    "hard_voting.fit(X_train, y_train) \n",
    "y_pred = hard_voting.predict(X_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy of Hard Voting model: %f\" % score)\n",
    "\n",
    "soft_voting = VotingClassifier(estimators=estimators, voting='soft') \n",
    "soft_voting.fit(X_train, y_train) \n",
    "y_pred = soft_voting.predict(X_test) \n",
    "\n",
    "score = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy of Soft Voting model: %f\" % score) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ebcd2-2ee1-4c80-9319-7e5ed429773a",
   "metadata": {},
   "source": [
    "## Weighted Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b5da8e-992a-48df-b391-382cff2a5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,model,weight):\n",
    "        self.model = model\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.model]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w\n",
    "\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model,X,y,scoring=\"neg_mean_squared_error\",cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a12e357-84ce-4939-95f9-07a97d3a21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Weighted Averaging model: 0.234249\n"
     ]
    }
   ],
   "source": [
    "estimators = [] \n",
    "estimators.append(LogisticRegression()) \n",
    "estimators.append(DecisionTreeRegressor())\n",
    "estimators.append(Lasso())\n",
    "estimators.append(Ridge())\n",
    "\n",
    "w1 = 0.2\n",
    "w2 = 0.3\n",
    "w3 = 0.4\n",
    "w4 = 0.1\n",
    "\n",
    "weight_avg = AverageWeight(model=estimators, weight=[w1, w2, w3, w4])\n",
    "score = rmse_cv(weight_avg, X, y)\n",
    "\n",
    "print(\"Accuracy of Weighted Averaging model: %f\" % score.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db43a45-4f0c-4308-909a-6fd1f9f276fb",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d668455-7770-438d-8613-ccd4d3660afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Blending model:  0.9941520467836257\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed)\n",
    "\n",
    "x_val = pd.DataFrame(X_val)\n",
    "x_test = pd.DataFrame(X_test)\n",
    "\n",
    "model1 = DecisionTreeClassifier()\n",
    "model1.fit(X_train, y_train)\n",
    "val_pred1=model1.predict(X_val)\n",
    "test_pred1=model1.predict(X_test)\n",
    "val_pred1=pd.DataFrame(val_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(X_train,y_train)\n",
    "val_pred2 = model2.predict(X_val)\n",
    "test_pred2 = model2.predict(X_test)\n",
    "val_pred2 = pd.DataFrame(val_pred2)\n",
    "test_pred2 = pd.DataFrame(test_pred2)\n",
    "\n",
    "df_val = pd.concat([x_val, val_pred1, val_pred2], axis=1)\n",
    "df_test = pd.concat([x_test, test_pred1, test_pred2], axis=1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(df_val, y_val)\n",
    "print(\"Accuracy of Blending model: \", model.score(df_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a4f38-7147-4060-bb91-88e424d97cf4",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a9bafd-a5f6-49a8-95f5-0da77514ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of: 0.961, std: (+/-) 0.030 [RandomForestClassifier]\n",
      "Mean of: 0.954, std: (+/-) 0.037 [Bagging RandomForestClassifier]\n",
      "\n",
      "Mean of: 0.967, std: (+/-) 0.028 [ExtraTreesClassifier]\n",
      "Mean of: 0.953, std: (+/-) 0.032 [Bagging ExtraTreesClassifier]\n",
      "\n",
      "Mean of: 0.930, std: (+/-) 0.029 [KNeighborsClassifier]\n",
      "Mean of: 0.931, std: (+/-) 0.029 [Bagging KNeighborsClassifier]\n",
      "\n",
      "Mean of: 0.914, std: (+/-) 0.029 [SVC]\n",
      "Mean of: 0.910, std: (+/-) 0.042 [Bagging SVC]\n",
      "\n",
      "Mean of: 0.954, std: (+/-) 0.025 [RidgeClassifier]\n",
      "Mean of: 0.935, std: (+/-) 0.024 [Bagging RidgeClassifier]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rg = RidgeClassifier()\n",
    "clf_array = [rf, et, knn, svc, rg]\n",
    "\n",
    "for clf in clf_array:\n",
    "    vanilla_scores = cross_val_score(clf, X, y, cv=10, n_jobs=-1)\n",
    "    bagging_clf = BaggingClassifier(clf,max_samples=0.4, max_features=10, random_state=seed)\n",
    "    bagging_scores = cross_val_score(bagging_clf, X, y, cv=10,n_jobs=-1)\n",
    "    \n",
    "    print (\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\".format(clf.__class__.__name__,vanilla_scores.mean(), vanilla_scores.std()))\n",
    "    print (\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\".format(clf.__class__.__name__,bagging_scores.mean(), bagging_scores.std()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36395316-387e-4778-ab52-7f71233e53f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.03) [Random Forest]\n",
      "Accuracy: 0.96 (+/- 0.02) [Extra Trees]\n",
      "Accuracy: 0.93 (+/- 0.03) [KNeighbors]\n",
      "Accuracy: 0.91 (+/- 0.03) [SVC]\n",
      "Accuracy: 0.95 (+/- 0.03) [Ridge Classifier]\n",
      "Accuracy: 0.96 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf = [rf, et, knn, svc, rg]\n",
    "eclf = VotingClassifier(estimators=[('Random Forests', rf), ('Extra Trees', et), ('KNeighbors', knn), ('SVC', svc), ('Ridge Classifier', rg)], voting='hard')\n",
    "for clf, label in zip([rf, et, knn, svc, rg, eclf], ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC', 'Ridge Classifier', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f04fe6-d76b-4255-900a-02388a2ad8c3",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d0709c-d9fc-4e6e-a6ee-15b7b805c7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.03) [Ada Boost]\n",
      "Accuracy: 0.95 (+/- 0.02) [Grad Boost]\n",
      "Accuracy: 0.95 (+/- 0.02) [XG Boost]\n",
      "Accuracy: 0.96 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier(random_state=seed)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "ada_boost.score(X_test,y_test)\n",
    "\n",
    "grad_boost= GradientBoostingClassifier(learning_rate=0.01,random_state=seed)\n",
    "grad_boost.fit(X_train, y_train)\n",
    "grad_boost.score(X_test,y_test)\n",
    "\n",
    "xgb_boost=XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "xgb_boost.fit(X_train, y_train)\n",
    "xgb_boost.score(X_test,y_test)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('Ada Boost', ada_boost), ('Grad Boost', grad_boost), ('XG Boost', xgb_boost)], voting='hard')\n",
    "clf = [rf, et, knn, svc, rg]\n",
    "for clf, label in zip([ada_boost, grad_boost, xgb_boost,eclf], ['Ada Boost','Grad Boost','XG Boost','Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
